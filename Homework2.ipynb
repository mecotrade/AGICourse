{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python version: %s' % sys.version)\n",
    "print('Numpy version: %s' % np.__version__)\n",
    "print('Tensorflow version: %s' % tf.__version__)\n",
    "print('Tensorflow datasets version: %s' % (tfds.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train, mnist_test), mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True, shuffle_files=True, split=['train', 'test'])\n",
    "mnist_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, возвращающую преобразование пары (картинка, номер класса) в нормированную картинку, плюс, возможно, номер класса, в зависимости от настроек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaler(scale=255, with_label=True):\n",
    "    \n",
    "    def rescale(x, y):\n",
    "        return 1 - x / scale\n",
    "    \n",
    "    def rescale_and_label(x, y):\n",
    "        return rescale(x), y\n",
    "    \n",
    "    return rescale_and_label if with_label else rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько примеров из MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "rescale = rescaler(255, with_label=False)\n",
    "for n, (x, y) in enumerate(mnist_train.take(15)):\n",
    "    plt.subplot(3, 5, n + 1)\n",
    "    plt.imshow(rescale(x, y), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution\n",
    "\n",
    "Цель этого задания - познакомиться с операцией деконволюции на примере фильтра, который увеличивает изображения в 2 раза с помощью билинейной интерполяции. Вместо того, чтобы выводить его из теоретических соображений, мы построим соответствующую модель и обучим её увеличивать изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.а\n",
    "\n",
    "Датасет MNIST состоит из пар `(X, y)`, где `X` это монохромное изображение 28x28, `y` это класс. Необходимо написать фукнцию, преобразующую эту пару в пару `(x, X)`, где `x` это уменьшенное в 2 раза изображение цифры, т.е. монохромное изображение 14x14. При этом значение пикселей в изображениях должны быть отнормированы на интервал `[0,1]`. Также если хочется видеть черные цифры на белом фоне, а не наоборот, можно инвертировать цвета: `x -> 1-x`.\n",
    "\n",
    "Определяем по аналогии с функцией `rescaler`.\n",
    "```\n",
    "tf.image.resize\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_size_to_full_size(scale=255):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.б\n",
    "\n",
    "Определить модель состоящую из одно слоя деконволюции с одним фильтром размера 3x3 и страйдом=2, без bias, переводящую монохромное изображение 14x14 в монохромное изображение 28x28. В качестве функции потерь используем среднеквадратичную ошибку. Опртимизатор - Adam с дефолтными настройками.\n",
    "```\n",
    "tf.keras.layers.Conv2DTranspose\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superresolution = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.в\n",
    "\n",
    "* Определить callback для использования во время обучения. По окончани каждой эпохи этот callback должен выводить все элементы фильтра деконволюции в виде чисел. \n",
    "* Обучить модель на 10 эпохах, используя `mnist_train` и `mnist_test` для валидации. В конце каждой эпохи можно контролировать элементы фильтра с помощью созданного callback-а\n",
    "* Какой в результате после обучения получается фильтр? Похож ли он на\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.25 & 0.5 & 0.25 \\\\\n",
    "0.5 & 1.0 & 0.5 \\\\\n",
    "0.25 & 0.5 & 0.25\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Если нет, то почему?\n",
    "```\n",
    "tf.keras.callbacks.Callback\n",
    "superresolution.fit(..., callbacks=[PrintKernelCallback(superresolution)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintKernelCallback(tf.keras.callbacks.Callback):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.г\n",
    "\n",
    "Определить регуляризацию для фильтра так, чтобы в результате получалась матрица\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.25 & 0.5 & 0.25 \\\\\n",
    "0.5 & 1.0 & 0.5 \\\\\n",
    "0.25 & 0.5 & 0.25\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Создать новую модель с этой регуляризацией, обучить её и убедиться, что теперь получается правильный фильтр.\n",
    "```\n",
    "tf.keras.regularizers.Regularizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superresolution_reg = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодер\n",
    "\n",
    "Цель этого задания - научиться стоить и обучать простейшие автоэнкодеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.а\n",
    "\n",
    "* Определить функцию превышения максимального уровня сигнала над средним значением шума\n",
    "$$\n",
    "PSNR = 10 \\log_{10} \\frac{\\max_{ij} y_{true, ij}^2}{MSE(y_{true}, y_{pred})}\n",
    "$$\n",
    "* Определить функцию, переводящую пару `(X, y)`, где `X` это монохромное изображение 28x28, `y` это класс, в пару двух одинаковых изображений `(X, X)`, аналогично заданию 1.а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_in_image_out(scale=255):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.б\n",
    "\n",
    "Определить метод, возвращающий энкодер, принимающий монохромное изображение 28x28, и выдающий латентный вектор заданной размерности. \n",
    "\n",
    "Архитектура энкодера:\n",
    "* слой свёртки с 32 фильтрами размерности 3х3 и страйдом 2, нелинейность - relu\n",
    "* слой свёртки с 64 фильтрами размерности 3х3 и страйдом 2, нелинейность - relu\n",
    "* полносвязный слой с выходной размерностью равной `latent_dim` \n",
    "\n",
    "![Encoder](homework2/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(latent_dim=10):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.в\n",
    "\n",
    "Определить метод, возвращающий декодер, принимающий латентный вектор заданной размерности и выдающий монохромное изображение 28x28.\n",
    "\n",
    "Архитектура декодера:\n",
    "* полносвязный слой, переводящий входной латентный вектор в вектор размерности 7\\*7\\*32\n",
    "* слой, переводящий вектор размерности 7\\*7\\*32 в тензор размерности \\[7, 7, 32\\]\n",
    "* слой деконволюции с 64 фильтрами размерности (3, 3), страйдом 2 и нелинейностью relu\n",
    "* слой деконволюции с 32 фильтрами размерности (3, 3), страйдом 2 и нелинейностью relu\n",
    "* слой деконволюции с 1 фильтром размерности (3, 3), страйдом 1 и нелинейностью sigmoid\n",
    "\n",
    "![Decoder](homework2/decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(latent_dim=10):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.г\n",
    "* Определить класс `AutoEncoder` при инициализации принимающий 2 параметра: сеть-энкодер, и сеть-декодер, при вызове возвращающий результат последовательного применеия к изображению энкодера и декодера.\n",
    "* Определить объект этого класса, модель `autoencoder`, с оптимизатором Adam(1e-4), среднеквадратичной функцией потерь, использующую метрику `PSNR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(tf.keras.Model):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразим пары исходное изображение - восстановленное изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(model, dataset, num_examples=10, figsize=(20, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    rescaler = image_in_image_out()\n",
    "    for n, (x, y) in enumerate(dataset.shuffle(1000).batch(1).take(num_examples)):\n",
    "        _, x_orig = rescaler(x, y)\n",
    "        plt.subplot(2, num_examples, n + 1)\n",
    "        plt.imshow(x_orig[0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, num_examples, n + 1 + num_examples)\n",
    "        plt.imshow(model(x_orig)[0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        plot_sample(self.model, self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.е\n",
    "\n",
    "Создать объект класса AutoEncoder, и обучить эту модель на 10 эпохах датасета `mnist_train`, выводя после каждой эпохи несколько примеров работы автоэнкодера. В качестве функции потерь использовать среднеквадратичную ошибку, оптимизатор - Adam со скоростью обучения 1e-4, в качестве метрики использовать созданную в задании 2.a функцию `PSNR`. Для визуального котроля качества обучения использовать `fit(..., callbacks=[PlotCallback(autoencoder, mnist_test)])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake\n",
    "\n",
    "В этом задании мы реализуем знаменитую технологию замены лиц, DeepFake. Однако, вместо того, чтобы работать с настоящими лицами, что требует погружения во многие детали и больших вычислительных мощностей, мы обучим DeepFake на цифрах. Т.е. мы обучим систему, переводящую, к примеру, семерки в единицы, с сохранением некотороых характерных черт, например, наклона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.а\n",
    "\n",
    "* Определить один общий энкодер \n",
    "* Создать 2 сети с архитектурой автоэнкодера, имеющих общий энкодер и разные декодеры, функция потерь - среднеквадратичная ошибка, оптимизатор - Adam(1e-4), метрика - PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_common = # your code\n",
    "\n",
    "deepfake_A = # your code\n",
    "\n",
    "deepfake_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.б\n",
    "\n",
    "* Выбрать 2 цифры, например, 7 и 8\n",
    "* Обучать попеременно первый и второй автоэнкодер по 1 эпохе на отфильтроывнных датасетах, например\n",
    "    * первый автоэнкодер обучается только на цифре 7\n",
    "    * второй автоэнкодер обучается только на цифре 8\n",
    "* Провести процедуру попеременного обучения 10 раз, после каждого раза для визуального контроля выводить\n",
    "    * результат преобразования первым автоэнкодером цифры 8 (не той, на которой он учился!)\n",
    "    * результат преобразования вторым автоэнкодером цифры 7 (не той, на которой он учился!)\n",
    "* Описать результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = 7\n",
    "digit_B = 1\n",
    "for epoch in range(10):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры\n",
    "\n",
    "Выполнив это код мы должны увидеть, что созданная цифра повторяет угол поворота исходной, как в настоящем deepfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rotate(model_A, model_B, digit_A, digit_B, angles=np.linspace(-0.5, 0.5, 11)):\n",
    "    for x, y in mnist_test.filter(lambda x, y: y == digit_A).shuffle(1000).take(1):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for n, angle in enumerate(angles):\n",
    "            x_rot = tfa.image.rotate(x, angle)\n",
    "            plt.subplot(2, 11, n + 1)\n",
    "            plt.imshow(1 - x_rot / 255, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            x_trans = model_A(1 - x_rot[np.newaxis, :] / 255)\n",
    "            plt.subplot(2, 11, n + 1 + 11)\n",
    "            plt.imshow(x_trans[0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    for x, y in mnist_test.filter(lambda x, y: y == digit_B).shuffle(1000).take(1):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for n, angle in enumerate(angles):\n",
    "            x_rot = tfa.image.rotate(x, angle)\n",
    "            plt.subplot(2, 11, n + 1)\n",
    "            plt.imshow(1 - x_rot / 255, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            x_trans = model_B(1 - x_rot[np.newaxis, :] / 255)\n",
    "            plt.subplot(2, 11, n + 1 + 11)\n",
    "            plt.imshow(x_trans[0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(deepfake_B, deepfake_A, digit_A, digit_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake + GAN\n",
    "\n",
    "В этом задании мы попробуем улучшить качество восстановленных изображений, добавив дискриминатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.a\n",
    "\n",
    "Определить функцию, возвращающую дискриминатор. Дискриминатор принимает на вход монохромные изображения 28x28 и возвращает одно число в интервале от 0 до 1, которое показывает степень уверенности дискриминатора в том, что ему бло предъявлено оригинальное (не ситезированное) изображение.\n",
    "\n",
    "Архитектура дискриминатора:\n",
    "* слой свёртки с 64 фильтрами размерности (3, 3), страйдом 2 и нелинейностью relu\n",
    "* слой свёртки с 32 фильтрами размерности (3, 3), страйдом 2 и нелинейностью relu\n",
    "* полносвязный слой с выходной размерностью 1 и нелинейностью sigmoid\n",
    "\n",
    "![Дискриминатор](homework2/discriminator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.б\n",
    "\n",
    "Определить\n",
    "* Общий энкодер\n",
    "* 2 автоэнкодера, имеющих общий энкодер и разные декодеры, функция потерь - среднеквадратичная ошибка, оптимизатор - Adam(1e-4)\n",
    "* 2 дискриминатора, оптимизатор - Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_common = # your code\n",
    "\n",
    "dfgan_A = # your code\n",
    "\n",
    "dfgan_B = # your code\n",
    "\n",
    "discriminator_A = # your code\n",
    "\n",
    "discriminator_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим итераторы над датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = 1\n",
    "digit_B = 8\n",
    "\n",
    "iter_A = iter(mnist_train.filter(lambda x, y: y == digit_A).map(rescaler(with_label=False)).shuffle(1000).batch(32).repeat())\n",
    "iter_B = iter(mnist_train.filter(lambda x, y: y == digit_B).map(rescaler(with_label=False)).shuffle(1000).batch(32).repeat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание  4.в\n",
    "\n",
    "Определить функцию обучения для двух автоэнкодеров и двух дискриминаторов\n",
    "* Автоэнкодеры учатся восстанавливать изображения, **каждый из своего класса**, например, первый учится востанавливать единицы, второй - восьмерки\n",
    "* Дискриминаторы учатся отличать восстановленные изображения от оригинальных, снова каждый в своем классе\n",
    "* В функции потерь дискриминаторов можно использовать `tf.keras.losses.BinaryCrossEntropy(label_smoothing=0.2)` **только для оригинальных изображений**. Реконструированные изображения используют обычную функцию потерь, без smoothing\n",
    "* На время отладки аннотацию `@tf.function` можно закомментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan_weight = 1e-3):\n",
    "    \n",
    "    # your code\n",
    "    \n",
    "    # loss_rec_A - L2 часть функции потерь для dfgan_A\n",
    "    # loss_rec_B - L2 часть функции потерь для dfgan_B\n",
    "    # loss_gan_A - GAN часть функции потерь для dfgan_A\n",
    "    # loss_gan_B - GAN часть функции потерь для dfgan_B\n",
    "    \n",
    "    loss_A = loss_rec_A + gan_weight * loss_gan_A\n",
    "    loss_B = loss_rec_B + gan_weight * loss_gan_B\n",
    "\n",
    "    # loss_dA - значение функции потерь для discriminator_A\n",
    "    # loss_dB - значение функции потерь для discriminator_B\n",
    "    # accuracy_dA - аккуратность discriminator_A\n",
    "    # accuracy_dB - аккуратность discriminator_B\n",
    "    \n",
    "    return loss_A, loss_B, loss_dA, loss_dB, accuracy_dA, accuracy_dB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем DeepFake + GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "log_every = 10\n",
    "plot_every = 200\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(num_steps)\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    loss_A, loss_B, loss_dA, loss_dB, accuracy_dA, accuracy_dB = train_step(1e-3)\n",
    "    if step % log_every == 0:\n",
    "        logs = [\n",
    "            ('loss_A', loss_A), \n",
    "            ('loss_B', loss_B), \n",
    "            ('loss_dA', loss_dA), \n",
    "            ('loss_dB', loss_dB), \n",
    "            ('accuracy_dA', accuracy_dA), \n",
    "            ('accuracy_dB', accuracy_dB)\n",
    "        ]\n",
    "        progbar.update(step, values=logs)        \n",
    "    if step % plot_every == 0:\n",
    "        plot_sample(dfgan_A, mnist_test.filter(lambda x, y: y == num_B))\n",
    "        plot_sample(dfgan_B, mnist_test.filter(lambda x, y: y == num_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(dfgan_B, dfgan_A, digit_A, digit_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN\n",
    "\n",
    "Альтернативный подход к замене одних объектов другими. И снова для простоты вместо того, чтобы превращать лошадей в зебр и обратно, мы будем превращать одни цифры в другие. При этом необязательно признаки отображаются в аналогичные признаки, например, не обязательно наклон будет отображаться в наклон. Возможно, признаки будут отображаться в какие-то другие признаки. Например, наклон вправо будет отбражаться в наклон влево. Или в толщину линии, рисующей цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5.а\n",
    "\n",
    "Определить \n",
    "* 2 сети с архитектурой автоэнкодера, будем называть их трансляторами, имеющих **различные энкодеры и различные декодеры**, оптимизатор - Adam(1e-4), эти сети должны переводить картинки из одного класса в другой и обратно\n",
    "* 2 дискриминатора, оптимизатор - Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_AB = # your code\n",
    "\n",
    "translator_BA = # your code\n",
    "\n",
    "discriminator_A = # your code\n",
    "\n",
    "discriminator_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим итераторы над датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = 4\n",
    "digit_B = 7\n",
    "\n",
    "iter_A = iter(mnist_train.filter(lambda x, y: y == digit_A).map(rescaler(with_label=False)).shuffle(1000).batch(32).repeat())\n",
    "iter_B = iter(mnist_train.filter(lambda x, y: y == digit_B).map(rescaler(with_label=False)).shuffle(1000).batch(32).repeat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5.б\n",
    "\n",
    "Определить функцию обучения для двух трансляторов и двух дискриминаторов\n",
    "* Трансляторы учатся восстанавливать изображения, после прямого и обратного перевода, в двух возможных порядках, наример, если мы превращаем 4 в 7 и наоборот, то трансляторы должны учить восстанвливать как 4 -> 7 -> 4, так и 7 -> 4 -> 7. Функция потерь для трансляторов - L1\n",
    "* Дискриминаторы учатся различать переведённое изображения от оригинальных, **каждый в своем классе**\n",
    "* В функции потерь дискриминаторов можно использовать `tf.keras.losses.BinaryCrossEntropy(label_smoothing=0.2)` **только для оригинальных изображений**. Реконструированные изображения используют обычную функцию потерь, без smoothing\n",
    "* На время отладки аннотацию `@tf.function` можно закомментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan_weight = 1e-3):\n",
    "    \n",
    "    # your code\n",
    "    \n",
    "    # loss_rec_A - L2 часть функции потерь для translator_AB(translator_BA(...))\n",
    "    # loss_rec_B - L2 часть функции потерь для translator_BA(translator_AB(...))\n",
    "    # loss_gan_A - GAN часть функции потерь для dfgan_A\n",
    "    # loss_gan_B - GAN часть функции потерь для dfgan_B\n",
    "    \n",
    "    loss_trans = loss_rec_A + loss_rec_B + gan_weight * (loss_gan_A + loss_gan_B)\n",
    "    \n",
    "    # loss_trans необходимо использовать для обучения обоих трансляторов!\n",
    "\n",
    "    # loss_dA - значение функции потерь для discriminator_A\n",
    "    # loss_dB - значение функции потерь для discriminator_B\n",
    "    # accuracy_dA - аккуратность discriminator_A\n",
    "    # accuracy_dB - аккуратность discriminator_B\n",
    "    \n",
    "    return loss_trans, loss_dA, loss_dB, accuracy_dA, accuracy_dB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем трансляторы (долго!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50000\n",
    "\n",
    "log_every = 10\n",
    "plot_every = 1000\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(num_steps)\n",
    "for step in range(num_steps):\n",
    "    loss_trans, loss_dA, loss_dB, accuracy_dA, accuracy_dB = train_step(gan_weight = 1e-3)\n",
    "    if step % log_every == 0:\n",
    "        logs = [\n",
    "            ('loss_trans', loss_trans), \n",
    "            ('loss_dA', loss_dA), \n",
    "            ('loss_dB', loss_dB), \n",
    "            ('accuracy_dA', accuracy_dA), \n",
    "            ('accuracy_dB', accuracy_dB)\n",
    "        ]\n",
    "        progbar.update(step, values=logs)\n",
    "        \n",
    "    if step % plot_every == 0:\n",
    "        plot_sample(translator_AB, mnist_test.filter(lambda x, y: y == num_B))\n",
    "        plot_sample(translator_BA, mnist_test.filter(lambda x, y: y == num_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(translator_BA, translator_AB, digit_A, digit_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 TF2",
   "language": "python",
   "name": "py38tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow_addons\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.utils import Progbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python version: %s' % sys.version)\n",
    "print('Numpy version: %s' % np.__version__)\n",
    "print('Tensorflow version: %s' % tf.__version__)\n",
    "print('Tensorflow datasets version: %s' % (tfds.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mnist_train, mnist_test), mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True, shuffle_files=True, split=['train', 'test'])\n",
    "mnist_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию, возвращающую преобразование пары (картинка, номер класса) в нормированную картинку, плюс, возможно, номер класса, в зависимости от настроек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescaler(scale=255):\n",
    "    \n",
    "    def rescale(x, y):\n",
    "        return 1 - x / scale\n",
    "    \n",
    "    return rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько примеров из MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "rescale = rescaler()\n",
    "for n, (x, y) in enumerate(mnist_train.take(15)):\n",
    "    plt.subplot(3, 5, n + 1)\n",
    "    plt.imshow(rescale(x, y), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Resolution\n",
    "\n",
    "Цель этого задания - познакомиться с операцией деконволюции на примере фильтра, который увеличивает изображения в 2 раза с помощью билинейной интерполяции. Вместо того, чтобы выводить его из теоретических соображений, мы построим соответствующую модель и обучим её увеличивать изображения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.а\n",
    "\n",
    "Датасет MNIST состоит из пар `(X, y)`, где `X` это монохромное изображение 28x28, `y` это класс. \n",
    "* Написать фукнцию, преобразующую эту пару в пару `(x, X)`, где `x` это уменьшенное в 2 раза изображение цифры, т.е. монохромное изображение 14x14. При этом значение пикселей в изображениях должны быть отнормированы на интервал $[0,1]$. Также если хочется видеть черные цифры на белом фоне, а не наоборот, можно инвертировать цвета: $x \\to 1-x$. Определяем по аналогии с функцией `rescaler`.\n",
    "* Используя `mnist_train` определить датасет, состоящий из пар (изображение 14x14, изображение 28x28), выдающий такие пары батчами по 32 пары. Не забыть перемешать! \n",
    "```\n",
    "tf.image.resize\n",
    "tf.data.Dataset.shuffle\n",
    "tf.data.Dataset.map\n",
    "tf.data.Dataset.batch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_size_to_full_size(scale=255):\n",
    "    def resize(x, y):\n",
    "        # your code\n",
    "        pass\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_superres = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.б\n",
    "\n",
    "Определить модель состоящую из одно слоя деконволюции \n",
    "* c одним фильтром размера 3x3\n",
    "* co страйдом=2\n",
    "* без bias\n",
    "* без нелинейности\n",
    "* `padding='SAME'`\n",
    "\n",
    "переводящую монохромное изображение 14x14 в монохромное изображение 28x28. В качестве функции потерь используем среднеквадратичную ошибку. Оптимизатор - `Adam` с настройками по-умолчанию.\n",
    "```\n",
    "tf.keras.Sequential\n",
    "tf.keras.layers.Conv2DTranspose\n",
    "tf.keras.optimizers.Adam\n",
    "tf.keras.losses.MeanSquaredError\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superresolution = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.в\n",
    "\n",
    "* Определить callback для использования во время обучения. По окончани каждой эпохи этот callback должен выводить все элементы фильтра деконволюции в виде чисел. \n",
    "* Обучить модель на 3 эпохах, используя `dataset_superres`. В конце каждой эпохи можно контролировать элементы фильтра с помощью созданного callback-а\n",
    "* Какой в результате после обучения получается фильтр? Похож ли он на\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0.25 & 0.5 & 0.25 \\\\\n",
    "0.5 & 1.0 & 0.5 \\\\\n",
    "0.25 & 0.5 & 0.25\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Если нет, то почему (как вы думаете)?\n",
    "```\n",
    "tf.keras.callbacks.Callback\n",
    "tf.keras.Model.fit(..., callbacks=[PrintKernelCallback(superresolution)])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintKernelCallback(tf.keras.callbacks.Callback):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.г\n",
    "\n",
    "* Определить регуляризацию для фильтра которая будет штрафовать модель за то, что фильтр отклоняется от следующих правил:\n",
    "  * все угловые элементы равны между собой\n",
    "  * серединные элементы для всех четырёх сторон (верхней и нижней строки, правого и левого ряда) равны между собой  \n",
    "* Создать новую модель с этой регуляризацией\n",
    "* Обучить эту модель на 3 эпохах и убедиться, что теперь получается правильный фильтр.\n",
    "```\n",
    "tf.keras.layers.Conv2DTranspose(..., kernel_regularizer=SymRegularizer())\n",
    "tf.keras.regularizers.Regularizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymRegularizer(tf.keras.regularizers.Regularizer):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superresolution_reg = # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодер\n",
    "\n",
    "Цель этого задания - научиться стоить и обучать простейшие автоэнкодеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.а\n",
    "\n",
    "* Определить функцию превышения максимального уровня сигнала над средним значением шума\n",
    "$$\n",
    "PSNR = 10 \\log_{10} \\frac{\\max_{ij} y_{true, ij}^2}{MSE(y_{true}, y_{pred})}\n",
    "$$\n",
    "* Определить функцию, переводящую пару `(X, y)`, где `X` это монохромное изображение 28x28, `y` это класс, в пару одинаковых изображений `(X, X)`, аналогично заданию **1.а**\n",
    "* Используя `mnist_train` определить датасет состоящий из пары одинаковых изображенией 28x28, батч размера 32, не забыть перемешать, аналогично заданию **1.a** \n",
    "```\n",
    "tf.experimental.numpy.log10\n",
    "tf.math.reduce_max(..., axis=[-1, -2, -3])\n",
    "tf.math.reduce_mean(..., axis=[-1, -2, -3])\n",
    "tf.math.square\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(y_true, y_pred):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_in_image_out(scale=255):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_auto = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.б\n",
    "\n",
    "Определить метод, возвращающий энкодер, принимающий монохромное изображение 28x28, и выдающий латентный вектор заданной размерности. \n",
    "\n",
    "Архитектура энкодера:\n",
    "* слой свёртки с 32 фильтрами размерности 3х3, страйдом 2, `padding='SAME'`, и нелинейностью `relu`\n",
    "* слой свёртки с 64 фильтрами размерности 3х3,страйдом 2, `padding='SAME'`, и нелинейностью `relu`\n",
    "* полносвязный слой с выходной размерностью равной `latent_dim` \n",
    "\n",
    "![Encoder](homework2/encoder.png)\n",
    "\n",
    "```\n",
    "tf.keras.Input\n",
    "tf.keras.layers.Conv2D\n",
    "tf.keras.layers.Flatten\n",
    "tf.keras.layers.Dense\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder(latent_dim=10):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.в\n",
    "\n",
    "Определить метод, возвращающий декодер, принимающий латентный вектор заданной размерности и выдающий монохромное изображение 28x28.\n",
    "\n",
    "Архитектура декодера:\n",
    "* полносвязный слой, переводящий входной латентный вектор в вектор размерности 7\\*7\\*32, с нелинейнойстью `relu`\n",
    "* слой, переводящий вектор размерности 7\\*7\\*32 в тензор размерности \\[7, 7, 32\\]\n",
    "* слой деконволюции с 64 фильтрами размерности (3, 3), страйдом 2, `padding='SAME'` и нелинейностью `relu`\n",
    "* слой деконволюции с 32 фильтрами размерности (3, 3), страйдом 2, `padding='SAME'` и нелинейностью `relu`\n",
    "* слой деконволюции с 1 фильтром размерности (3, 3), страйдом 1, `padding='SAME'` и нелинейностью `sigmoid`\n",
    "\n",
    "![Decoder](homework2/decoder.png)\n",
    "\n",
    "```\n",
    "tf.keras.layers.Reshape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder(latent_dim=10):\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.г\n",
    "* Определить класс `AutoEncoder` при инициализации принимающий 2 параметра: сеть-энкодер, и сеть-декодер, при вызове возвращающий результат последовательного применеия к изображению энкодера и декодера.\n",
    "* Определить объект этого класса, модель `autoencoder`, с оптимизатором `Adam(1e-4)`, среднеквадратичной функцией потерь, использующую метрику `PSNR`.\n",
    "```\n",
    "tf.keras.Model\n",
    "tf.keras.Model.compile(..., metrics=[PSNR])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(tf.keras.Model):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.е\n",
    "\n",
    "Обучить построенный автоэнкодер на 10 эпохах датасета `dataset_auto`, построенного в задании **2.а**, выводя после каждой эпохи несколько примеров работы автоэнкодера. В качестве функции потерь использовать среднеквадратичную ошибку, оптимизатор - Adam со скоростью обучения 1e-4, в качестве метрики использовать созданную в задании **2.a** функцию `PSNR`. Для визуального котроля качества обучения использовать `fit(..., callbacks=[PlotCallback(autoencoder, mnist_test)])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Служебная функция отображающая пары исходное изображение - восстановленное изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(model, dataset, num_examples=10, figsize=(20, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    rescaler = image_in_image_out()\n",
    "    for n, (x, y) in enumerate(dataset.shuffle(1000).batch(1).take(num_examples)):\n",
    "        _, x_orig = rescaler(x, y)\n",
    "        plt.subplot(2, num_examples, n + 1)\n",
    "        plt.imshow(x_orig[0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.subplot(2, num_examples, n + 1 + num_examples)\n",
    "        plt.imshow(model(x_orig)[0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, model, dataset):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        plot_sample(self.model, self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training, your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake\n",
    "\n",
    "В этом задании мы реализуем знаменитую технологию замены лиц, DeepFake. Однако, вместо того, чтобы работать с настоящими лицами, что требует погружения во многие детали и больших вычислительных мощностей, мы обучим DeepFake на цифрах. Т.е. мы обучим систему, переводящую, к примеру, семерки в единицы, с сохранением некотороых характерных черт, например, наклона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.а\n",
    "\n",
    "* Определить один общий энкодер \n",
    "* Создать 2 сети с архитектурой автоэнкодера, имеющих общий энкодер и разные декодеры, функция потерь - среднеквадратичная ошибка, оптимизатор - `Adam(1e-4)`, метрика - `PSNR`, аналогично заданию **2.г**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_common = # your code\n",
    "\n",
    "deepfake_A = # your code\n",
    "\n",
    "deepfake_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.б\n",
    "* Выбрать 2 цифры, например, 7 и 8\n",
    "* Используя `mnist_train` определить 2 датасета таким образом, чтобы первый содержал только изображение первой цифры, например, 7, а второй - только второй цифры, например, 8, состоящий из пар двух одинаковых изображенией 28x28, батч размера 32, не забыть перемешать, аналогично заданию **1.a** \n",
    "* Используя `mnist_test` определить 2 датасета таким образом, чтобы первый содержал только изображение первой цифры, например, 7, а второй - только второй цифры, например, 8, превращать пару (изображение, метка) в пару одинаковых изображений **не нужно**, батч тоже не нужно делать\n",
    "```\n",
    "tf.data.Dataset.filter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = # a digit between 0 and 9 on your choice\n",
    "digit_B = # a digit between 0 and 9 on your choice\n",
    "\n",
    "dataset_A = # your code\n",
    "dataset_B = # your code\n",
    "\n",
    "dataset_test_A = # your code\n",
    "dataset_test_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3.в\n",
    "\n",
    "* Обучить попеременно первый и второй автоэнкодер по 1 эпохе на отфильтрованных датасетах, например\n",
    "    * первый автоэнкодер обучается только на цифре 7\n",
    "    * второй автоэнкодер обучается только на цифре 8\n",
    "* Провести процедуру попеременного обучения 10 раз, после каждого раза для визуального контроля выводить\n",
    "    * результат преобразования первым автоэнкодером цифры 8 (не той, на которой он учился!)\n",
    "    * результат преобразования вторым автоэнкодером цифры 7 (не той, на которой он учился!)\n",
    "* Описать результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры\n",
    "\n",
    "Выполнив это код мы должны увидеть, что созданная цифра повторяет угол поворота исходной, как в настоящем deepfake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rotate(model_A, model_B, digit_A, digit_B, angles=np.linspace(-0.5, 0.5, 11)):\n",
    "    for x, y in mnist_test.filter(lambda x, y: y == digit_A).shuffle(1000).take(1):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for n, angle in enumerate(angles):\n",
    "            x_rot = tfa.image.rotate(x, angle)\n",
    "            plt.subplot(2, 11, n + 1)\n",
    "            plt.imshow(1 - x_rot / 255, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            x_trans = model_A(1 - x_rot[np.newaxis, :] / 255)\n",
    "            plt.subplot(2, 11, n + 1 + 11)\n",
    "            plt.imshow(x_trans[0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "    for x, y in mnist_test.filter(lambda x, y: y == digit_B).shuffle(1000).take(1):\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        for n, angle in enumerate(angles):\n",
    "            x_rot = tfa.image.rotate(x, angle)\n",
    "            plt.subplot(2, 11, n + 1)\n",
    "            plt.imshow(1 - x_rot / 255, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            x_trans = model_B(1 - x_rot[np.newaxis, :] / 255)\n",
    "            plt.subplot(2, 11, n + 1 + 11)\n",
    "            plt.imshow(x_trans[0], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(deepfake_B, deepfake_A, digit_A, digit_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake + GAN\n",
    "\n",
    "В этом задании мы попробуем улучшить качество восстановленных изображений, добавив дискриминатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4.a\n",
    "\n",
    "Определить функцию, возвращающую дискриминатор. Дискриминатор принимает на вход монохромные изображения 28x28 и возвращает одно число в интервале от 0 до 1, которое показывает степень уверенности дискриминатора в том, что ему было предъявлено оригинальное (не ситезированное) изображение.\n",
    "\n",
    "Архитектура дискриминатора:\n",
    "* слой свёртки с 64 фильтрами размерности (3, 3), страйдом 2 и нелинейностью `relu`\n",
    "* слой свёртки с 32 фильтрами размерности (3, 3), страйдом 2 и нелинейностью `relu`\n",
    "* полносвязный слой с выходной размерностью 1 и нелинейностью `sigmoid`\n",
    "\n",
    "![Дискриминатор](homework2/discriminator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    # your code\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.б\n",
    "\n",
    "Определить\n",
    "* Общий энкодер\n",
    "* 2 автоэнкодера, имеющих общий энкодер и разные декодеры, оптимизатор - `Adam(1e-4)`\n",
    "* 2 дискриминатора, оптимизатор - `Adam(1e-4)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_common = # your code\n",
    "\n",
    "dfgan_A = # your code\n",
    "\n",
    "dfgan_B = # your code\n",
    "\n",
    "discriminator_A = # your code\n",
    "\n",
    "discriminator_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4.в\n",
    "\n",
    "Используя `mnist_train` определить 2 датасета таким образом, чтобы первый содержал только изображение первой цифры, например, 1, а второй - только второй цифры, например, 8. Второе изображение и класс изображение (цифра) не нужны, но мы хотим отнормировать значение пикселей на интервал $[0, 1]$, поэтому мы преобразуем изображения используя метод `rescaler` из начала ноутбука. Используем батч размера 32, и не забываем перемешивать! Действует аналогично заданию **1.a**.\n",
    "\n",
    "Важное отличие: теперь мы хотим, чтобы все батчи имели размер 32, даже те, которые попадают на конец датасета, и для которых ровно 32-х элементнов может не хватить. Если последнему батчу не хватает элементов до полного размера, мы такой батч отбрасываем (раньше использовали). Кроме того, теперь мы не будет использовать метод `tf.keras.Model.fit` для обучения моделей, вместо этого мы будем писать логику обучения в явном виде. Поэтому нам понадобится бесконечный датасет, для получения которого мы закольцуем имеющийся.\n",
    "```\n",
    "tf.data.Dataset.batch(..., drop_remainder=True)\n",
    "tf.data.Dataset.repeat\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = # a digit between 0 and 9 on your choice\n",
    "digit_B = # a digit between 0 and 9 on your choice\n",
    "\n",
    "dataset_A = # your code\n",
    "dataset_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим итераторы над датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_A = iter(dataset_A)\n",
    "iter_B = iter(dataset_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание  4.г\n",
    "\n",
    "Определить функцию обучения для двух автоэнкодеров и двух дискриминаторов\n",
    "* Автоэнкодеры учатся восстанавливать изображения, **каждый из своего класса**, например, первый учится востанавливать единицы, второй - восьмерки\n",
    "* Дискриминаторы учатся отличать восстановленные изображения от оригинальных, снова каждый в своем классе\n",
    "* В функции потерь дискриминаторов можно использовать `tf.keras.losses.BinaryCrossEntropy(label_smoothing=0.2)` **только для оригинальных изображений**. Реконструированные изображения используют обычную функцию потерь, без smoothing\n",
    "* На время отладки аннотацию `@tf.function` можно закомментировать\n",
    "```\n",
    "tf.GradientTape\n",
    "tf.GradientTape.gradient\n",
    "tf.keras.optimizers.Optimizer.apply_gradients\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_batch = tf.ones(shape=(32, 1))\n",
    "zeros_batch = tf.ones(shape=(32, 1))\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "bce_smooth = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan_weight = 1e-3):\n",
    "    \n",
    "    # your code\n",
    "    \n",
    "    # loss_rec_A - L2 часть функции потерь для dfgan_A\n",
    "    # loss_rec_B - L2 часть функции потерь для dfgan_B\n",
    "    # loss_gan_A - GAN часть функции потерь для dfgan_A\n",
    "    # loss_gan_B - GAN часть функции потерь для dfgan_B\n",
    "    \n",
    "    loss_A = loss_rec_A + gan_weight * loss_gan_A\n",
    "    loss_B = loss_rec_B + gan_weight * loss_gan_B\n",
    "\n",
    "    # loss_dA - значение функции потерь для discriminator_A\n",
    "    # loss_dB - значение функции потерь для discriminator_B\n",
    "    # accuracy_dA - аккуратность discriminator_A\n",
    "    # accuracy_dB - аккуратность discriminator_B\n",
    "    \n",
    "    return loss_A, loss_B, loss_dA, loss_dB, accuracy_dA, accuracy_dB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем DeepFake + GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "log_every = 10\n",
    "plot_every = 200\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(num_steps)\n",
    "for step in range(num_steps):\n",
    "    \n",
    "    loss_A, loss_B, loss_dA, loss_dB, accuracy_dA, accuracy_dB = train_step(1e-3)\n",
    "    if step % log_every == 0:\n",
    "        logs = [\n",
    "            ('loss_A', loss_A), \n",
    "            ('loss_B', loss_B), \n",
    "            ('loss_dA', loss_dA), \n",
    "            ('loss_dB', loss_dB), \n",
    "            ('accuracy_dA', accuracy_dA), \n",
    "            ('accuracy_dB', accuracy_dB)\n",
    "        ]\n",
    "        progbar.update(step, values=logs)        \n",
    "    if step % plot_every == 0:\n",
    "        plot_sample(dfgan_A, mnist_test.filter(lambda x, y: y == digit_B))\n",
    "        plot_sample(dfgan_B, mnist_test.filter(lambda x, y: y == digit_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(dfgan_B, dfgan_A, digit_A, digit_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN\n",
    "\n",
    "Альтернативный подход к замене одних объектов другими. И снова для простоты вместо того, чтобы превращать лошадей в зебр и обратно, мы будем превращать одни цифры в другие. При этом необязательно признаки отображаются в аналогичные признаки, например, не обязательно наклон будет отображаться в наклон. Возможно, признаки будут отображаться в какие-то другие признаки. Например, наклон вправо будет отбражаться в наклон влево. Или в толщину линии, рисующей цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5.а\n",
    "\n",
    "Определить \n",
    "* 2 сети с архитектурой автоэнкодера, будем называть их трансляторами, имеющих **различные энкодеры и различные декодеры**, оптимизатор - `Adam(1e-4)`, эти сети должны переводить картинки из одного класса в другой и обратно\n",
    "* 2 дискриминатора, оптимизатор - `Adam(1e-4)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_AB = # your code\n",
    "\n",
    "translator_BA = # your code\n",
    "\n",
    "discriminator_A = # your code\n",
    "\n",
    "discriminator_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5.б\n",
    "\n",
    "Аналогично заданию **4.в** определелить с помощью `mnist_train` 2 датасета для двух выбранных чисел. Так же, как и в задании **4.в** отбрасываем неполные батчи в конце датасета, нормируем значения пикселей на интервал $[0, 1]$ и закольцовываем датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_A = # a digit between 0 and 9 on your choice\n",
    "digit_B = # a digit between 0 and 9 on your choice\n",
    "\n",
    "dataset_A = # your code\n",
    "dataset_B = # your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим итераторы над датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_A = iter(dataset_A)\n",
    "iter_B = iter(dataset_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5.в\n",
    "\n",
    "Определить функцию обучения для двух трансляторов и двух дискриминаторов\n",
    "* Трансляторы учатся восстанавливать изображения, после прямого и обратного перевода, в двух возможных порядках, наример, если мы превращаем 4 в 7 и наоборот, то трансляторы должны учить восстанавливать как $4 \\to 7 \\to 4$, так и $7 \\to 4 \\to 7$. Функция потерь для трансляторов - L1\n",
    "* Дискриминаторы учатся различать переведённое изображения от оригинальных, **каждый в своем классе**\n",
    "* В функции потерь дискриминаторов можно использовать `tf.keras.losses.BinaryCrossEntropy(label_smoothing=0.2)` **только для оригинальных изображений**. Реконструированные изображения используют обычную функцию потерь, без smoothing\n",
    "* На время отладки аннотацию `@tf.function` можно закомментировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gan_weight = 1e-3):\n",
    "    \n",
    "    # your code\n",
    "    \n",
    "    # loss_rec_A - L2 часть функции потерь для translator_AB(translator_BA(...))\n",
    "    # loss_rec_B - L2 часть функции потерь для translator_BA(translator_AB(...))\n",
    "    # loss_gan_A - GAN часть функции потерь для dfgan_A\n",
    "    # loss_gan_B - GAN часть функции потерь для dfgan_B\n",
    "    \n",
    "    loss_trans = loss_rec_A + loss_rec_B + gan_weight * (loss_gan_A + loss_gan_B)\n",
    "    \n",
    "    # loss_trans необходимо использовать для обучения обоих трансляторов!\n",
    "\n",
    "    # loss_dA - значение функции потерь для discriminator_A\n",
    "    # loss_dB - значение функции потерь для discriminator_B\n",
    "    # accuracy_dA - аккуратность discriminator_A\n",
    "    # accuracy_dB - аккуратность discriminator_B\n",
    "    \n",
    "    return loss_trans, loss_dA, loss_dB, accuracy_dA, accuracy_dB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучаем трансляторы (долго!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50000\n",
    "\n",
    "log_every = 10\n",
    "plot_every = 1000\n",
    "\n",
    "progbar = tf.keras.utils.Progbar(num_steps)\n",
    "for step in range(num_steps):\n",
    "    loss_trans, loss_dA, loss_dB, accuracy_dA, accuracy_dB = train_step(gan_weight = 1e-3)\n",
    "    if step % log_every == 0:\n",
    "        logs = [\n",
    "            ('loss_trans', loss_trans), \n",
    "            ('loss_dA', loss_dA), \n",
    "            ('loss_dB', loss_dB), \n",
    "            ('accuracy_dA', accuracy_dA), \n",
    "            ('accuracy_dB', accuracy_dB)\n",
    "        ]\n",
    "        progbar.update(step, values=logs)\n",
    "        \n",
    "    if step % plot_every == 0:\n",
    "        plot_sample(translator_AB, mnist_test.filter(lambda x, y: y == digit_B))\n",
    "        plot_sample(translator_BA, mnist_test.filter(lambda x, y: y == digit_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вращаем цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rotate(translator_BA, translator_AB, digit_A, digit_B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 TF2",
   "language": "python",
   "name": "py39tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
